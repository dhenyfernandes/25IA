{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80dd1797-10a3-4b84-a3d4-59a1ebf8842c",
   "metadata": {},
   "source": [
    "# Discovering Exoplanets using XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc89c957-8ce7-4da5-bbcd-d2aefb2e0974",
   "metadata": {},
   "source": [
    "Duas principais razões para este notebook existir:\n",
    "\n",
    "Obter prática num estudo ponta-a-ponta usando XGBoost\n",
    "Lidar com dataset desbalanceado\n",
    "Nosso estudo se concentrará em analisar dados de luz para predizer exoplanetas (planetas orbitando outras estrelas) no universo. Descobrir exoplanetas a partir da luz das estrelas requer a medição de flutuações de luz em intervalos de tempo prolongados. Como a mudança na luz geralmente é muito pequena, não é fácil determinar se um exoplaneta está realmente presente.\n",
    "\n",
    "Este conjunto de dados de exoplanetas foi retirado do Telescópio Espacial Kepler da NASA, Campanha 3, verão de 2016. As informações sobre a fonte de dados estão disponíveis no Kaggle em [link](https://www.kaggle.com/datasets/keplersmachines/kepler-labelled-time-series-data). De todas as estrelas no conjunto de dados, 5.050 não possuem exoplanetas, enquanto 37 possuem exoplanetas.\n",
    "\n",
    "Vamos Começar com um pequeno subconjunto dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eecccfc-01d9-40b3-a056-8da7a2a2c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "df = pd.read_csv('bases/exoplanets.csv', nrows=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84772704-a238-4ce7-99c0-539636b33dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b62d5d-f593-4cb6-97f3-3907724255a5",
   "metadata": {},
   "source": [
    "O grande número de colunas (3198) listadas abaixo do DataFrame faz sentido. Ao procurar mudanças periódicas na luz, você precisa de pontos de dados suficientes para encontrar a periodicidade. As revoluções (movimento em torno do sol) dos planetas dentro do nosso próprio sistema solar variam de 88 dias (Mercúrio) a 165 anos (Netuno). Se os exoplanetas forem detectados, os pontos de dados devem ser examinados com frequência suficiente para não perder o trânsito do planeta quando o planeta orbitar na frente da estrela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6fded2-7f89-48c6-b852-47afca12c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LABEL'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83488d7-b6ca-454c-b974-8d3d2baa2795",
   "metadata": {},
   "source": [
    "A expectativa é que quando um exoplaneta bloquear a luz de uma estrela, o fluxo de luz diminua. Se as quedas no fluxo ocorrerem periodicamente, um exoplaneta é provavelmente o motivo, pois, por definição, um planeta é um objeto grande que orbita uma estrela.\n",
    "\n",
    "Vamos visualizar os dados criando gráfico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abfd49f-1769-4ae9-a836-ff793e48682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "X = df.iloc[:,1:]\n",
    "y = df.iloc[:,0]\n",
    "\n",
    "def light_plot(index):\n",
    "    y_vals = X.iloc[index]\n",
    "    x_vals = np.arange(len(y_vals))\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.xlabel('Number of Observations')\n",
    "    plt.ylabel('Light Flux')\n",
    "    plt.title('Light Plot ' + str(index), size=15)\n",
    "    plt.plot(x_vals, y_vals)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad03ff1-0563-4ce5-b522-ff2a4bf78e8e",
   "metadata": {},
   "source": [
    "A função light_plot recebe como entrada o índice dos dados (a linha) que plota todos os pontos de dados como coordenadas y (o fluxo de luz) e o número de observações como coordenadas x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c173e9-5d49-4ebf-a3d4-4f9f17243fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_plot(0) # explaneta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccfc95e-2630-4148-a90a-172e0db77946",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_plot(37)# nao-exoplaneta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9ee0c8-0a02-47db-a817-b8994fdbdac1",
   "metadata": {},
   "source": [
    "Há quedas claras nos dados, mas não são periódicas ao longo do gráfico. A frequência das quedas não se repete de forma consistente. Apenas esta evidência não é suficiente determinar a presença de um exoplaneta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce3b3d-f885-4a18-83e8-9ca04043304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_plot(1) # exoplaneta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fd7c05-d2dd-4023-b6d0-f325227818de",
   "metadata": {},
   "source": [
    "O gráfico mostra uma periodicidade clara com grandes quedas no fluxo de luz, tornando um exoplaneta extremamente provável! Se todos os gráficos fossem tão claros, o aprendizado de máquina seria desnecessário. Como os outros gráficos revelam, concluir que um exoplaneta está presente geralmente não é tão claro.\n",
    "\n",
    "> Embora esse conjunto de dados seja uma série temporal, o objetivo não é prever o fluxo de luz para a próxima unidade de tempo, mas classificar a estrela com base em todos os dados. A este respeito, classificadores de aprendizado de máquina podem ser usados para prever se uma determinada estrela hospeda um exoplaneta. A ideia é treinar o classificador nos dados fornecidos, que por sua vez podem ser usados para prever exoplanetas em novos dados. Aqui, tentaremos classificar os exoplanetas dentro dos dados usando o XGBClassifier. Antes de passarmos para classificar os dados, devemos primeiro preparar os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97b1240-6288-415f-8b76-e4ec1ce3e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc1c57f-7c78-4320-88a0-34aec881c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para cada coluna e, depois, para somar todas as colunas\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c9c1f-f791-45e6-bd3c-1f3dc6e0a8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b7ca08-0a78-422d-a622-e64ca611f868",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(booster='gbtree', objective='binary:logistic', random_state=2, verbosity=0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Score: ' + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f6b446-bcb6-4540-bbbd-74f48d583b13",
   "metadata": {},
   "source": [
    "Pergunta: você obteve 89% de acurácia, mas os exoplanetas representam 10% dos dados, então como você sabe que seus resultados não são melhores do que um modelo que não prevê exoplanetas 100% do tempo?\n",
    "\n",
    "> Aí está a questão. Se o modelo determinar que nenhuma estrela contém exoplanetas, sua acurácia será de aproximadamente 90%, pois 9 em cada 10 estrelas não contêm exoplanetas.\n",
    "\n",
    "> com dados desbalanceados, acurácia não é suficiente\n",
    "\n",
    "> podemos usar a matrix de confusao para analisar melhor o resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e8c9c7-7f35-4b58-87a8-cbcc98e8f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# 86 nao-exoplanetas corretamente classificados e apenas 3 exoplanetas corretamente classificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305ee99d-ccac-47d9-8229-a993baa6f2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac61496c-5c3c-40bd-8528-58c4194e11c6",
   "metadata": {},
   "source": [
    "Ao escolher um método de score, é fundamental entender o objetivo. O objetivo no conjunto de dados Exoplanet é encontrar exoplanetas. Isso é óbvio. O que não é óbvio é como selecionar o melhor método de score para alcançar os resultados desejados.\n",
    "\n",
    "Imagine dois cenários diferentes:\n",
    "\n",
    "* Cenário 1: Das 4 estrelas de exoplanetas que o modelo de aprendizado de máquina prevê, 3 são na verdade estrelas de exoplanetas: precision = 3/4 = 75%.\n",
    "\n",
    "* Cenário 2: Das 12 estrelas de exoplanetas, o modelo prevê corretamente 8 estrelas de exoplanetas. recall = 8/12 = 66%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ad48df-69e1-4d25-a9f9-3f858498de9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "A resposta é que depende. O Recall é ideal para sinalizar possíveis casos positivos (exoplanetas) com o objetivo de encontrar todos eles. Precision é ideal para garantir que as previsões (exoplanetas) sejam realmente positivas.\n",
    "\n",
    "Supondo que o objetivo do modelo de aprendizado de máquina seja encontrar o maior número possível de exoplanetas, o recall é uma excelente escolha. Por quê? Recall nos diz quantas das 12 estrelas de exoplanetas foram encontradas (2/12, 5/12, 12/12)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d9c080-9b5e-49c5-a565-7dba03ef1b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test, y_pred, pos_label=2) #deixando claro que a classe positiva é a 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d72361-c781-48f0-b6ea-e6488bfbfccf",
   "metadata": {},
   "source": [
    "## Tratando dados desbalanceados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3b70ba-bc0a-4406-9c2a-96b05529cc0a",
   "metadata": {},
   "source": [
    "Agora que temos um método de score apropriado para descobrir exoplanetas, é hora de explorar estratégias como resampling, undersampling e oversampling para corrigir os dados desequilibrados que causam a recall baixo.\n",
    "\n",
    "* Uma estratégia para neutralizar dados desequilibrados é reamostrar os dados. É possível subamostrar os dados reduzindo as linhas da classe majoritária e superamostrando os dados repetindo as linhas da classe minoritária.\n",
    "\n",
    "Vamos escrever uma função que nos permite subamostrar os dados por qualquer número de linhas. A função a seguir usa o XGBClassifier e o número de linhas como entrada e produz confusion matrix, classification report e recall score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8794a79-8e22-4238-ac1d-0466943cb4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_clf(model, nrows):\n",
    "\n",
    "    df = pd.read_csv('bases/exoplanets.csv', nrows=nrows)\n",
    "    # Split data into X and y\n",
    "    X = df.iloc[:,1:]\n",
    "    y = df.iloc[:,0]\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)\n",
    "\n",
    "    # Fit xg_reg to training set\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict labels of test set, y_pred\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    score = recall_score(y_test, y_pred, pos_label=2)\n",
    "    \n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b70be7-fb73-499c-8445-80bb6f3ece72",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf(XGBClassifier(random_state=2), nrows=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdced61-ad5e-46c7-9a57-338bfed36e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf(XGBClassifier(random_state=2), nrows=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc05056-acb3-451d-b40e-85164dd4df1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf(XGBClassifier(random_state=2), nrows=74)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2870946-0355-4795-883b-4e00e7ef65ac",
   "metadata": {},
   "source": [
    "Outra técnica de reamostragem é a oversampling. Em vez de eliminar linhas, oversampling adiciona linhas copiando e redistribuindo os casos positivos.\n",
    "\n",
    "Nossa estratégia é a seguinte:\n",
    "\n",
    "* Crie um novo DataFrame que copie os casos positivos nove vezes.\n",
    "\n",
    "* Concatene um novo DataFrame com o original para obter uma proporção de 10-10.\n",
    "\n",
    "Antes de prosseguir, um aviso. Se os dados forem reamostrados antes de serem divididos em conjuntos de treinamento e teste, o recall será inflado.\n",
    "\n",
    "Na reamostragem, serão feitas nove cópias dos casos positivos. Depois de dividir esses dados em conjuntos de treinamento e teste, as cópias provavelmente estarão contidas em ambos os conjuntos. Portanto, o conjunto de teste conterá a maioria dos mesmos pontos de dados que o conjunto de treinamento.\n",
    "\n",
    "A estratégia apropriada é dividir os dados em um conjunto de treinamento e teste primeiro e depois reamostrar os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e14a88-5d64-4646-8de6-82a216c3c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(y_train, X_train, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca5fe95-d9f9-4669-8aa1-492e3ee30434",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.DataFrame(np.repeat(df_train[df_train['LABEL']==2].values,9,axis=0))\n",
    "newdf.columns = df_train.columns\n",
    "df_train_resample = pd.concat([df_train, newdf])\n",
    "\n",
    "df_train_resample['LABEL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189aed9-d786-4b5a-a4b5-0fce49eefec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resample = df_train_resample.iloc[:,1:]\n",
    "y_train_resample = df_train_resample.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2439ee28-b7f7-4f2c-ae77-d59e790ace7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the XGBRegressor, xg_reg\n",
    "model = XGBClassifier(random_state=2, verbosity=0)\n",
    "\n",
    "# Fit xg_reg to training set\n",
    "model.fit(X_train_resample, y_train_resample)\n",
    "\n",
    "# Predict labels of test set, y_pred\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "score = recall_score(y_test, y_pred, pos_label=2)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae65c271-84e8-430f-873d-cf1259637015",
   "metadata": {},
   "source": [
    "Melhoramos um pouco o recall, mas aindaa longe do desejado. Vamos fazer um tunning dos hiperparametros do XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0806ff-85e3-454c-97d9-5b0bfa6814c6",
   "metadata": {},
   "source": [
    "## Tuning XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915eb50e-9520-4f84-a9b4-641f9df49f70",
   "metadata": {},
   "source": [
    "vamos ajustar e dimensionar o XGBClassifier para obter o melhor valor de recall_score possível para o conjunto de dados Exoplanets. Primeiro, você ajustará os pesos usando scale_pos_weight e, em seguida, executará pesquisas de grade para encontrar a melhor combinação de hiperparâmetros. Além disso, você pontuará modelos para diferentes subconjuntos de dados antes de consolidar e analisar os resultados.\n",
    "\n",
    "Scale_pos_weight é um hiperparâmetro usado para dimensionar o peso positivo. A ênfase aqui no positivo é importante porque o XGBoost assume que um valor alvo de 1 é positivo e um valor alvo de 0 é negativo.\n",
    "\n",
    "No conjunto de dados Exoplanet, usamos o padrão 1 como negativo e 2 como positivo, conforme fornecido pelo conjunto de dados. Agora vamos mudar para 0 como negativo e 1 como positivo usando o método .replace()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ae2f83-250f-465a-a126-c4fb9f8b2801",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LABEL'] = df['LABEL'].replace(1, 0)\n",
    "df['LABEL'] = df['LABEL'].replace(2, 1)\n",
    "\n",
    "df['LABEL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3909f779-047b-474c-82ec-29fb53263d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y\n",
    "X = df.iloc[:,1:]\n",
    "y = df.iloc[:,0]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f26bb7-df9c-4308-b2a8-b4523d2d289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(scale_pos_weight=10, random_state=2,verbosity=0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels of test set, y_pred\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "score = recall_score(y_test, y_pred)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(score) # o mesmo resultado que foi obtido usando oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1cca5b-963d-47c9-a2c1-dcbcc65310ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa3d75-552c-44d2-bcb7-f22d992d9b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline\n",
    "kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=2)\n",
    "\n",
    "model = XGBClassifier(scale_pos_weight=10, random_state=2,verbosity=0)\n",
    "\n",
    "# Obtain scores of cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=kfold, scoring='recall')\n",
    "\n",
    "# Display accuracy\n",
    "print('Recall: ', scores)\n",
    "\n",
    "# Display mean accuracy\n",
    "print('Recall mean: ', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3037cf05-d7a1-447c-a5ed-8ad52b3e9d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(params, random=False, X=X, y=y, model=XGBClassifier(random_state=2, scale_pos_weight=10,\n",
    "                                                                   verbosity=0, use_label_encoder=False)): \n",
    "    \n",
    "    xgb = model\n",
    "    \n",
    "    if random:\n",
    "        grid = RandomizedSearchCV(xgb, params, cv=kfold, n_jobs=-1, random_state=2, scoring='recall')\n",
    "    else:\n",
    "        # Instantiate GridSearchCV as grid_reg\n",
    "        grid = GridSearchCV(xgb, params, cv=kfold, n_jobs=-1, scoring='recall')\n",
    "    \n",
    "    # Fit grid_reg on X_train and y_train\n",
    "    grid.fit(X, y)\n",
    "\n",
    "    # Extract best params\n",
    "    best_params = grid.best_params_\n",
    "\n",
    "    # Print best params\n",
    "    print(\"Best params:\", best_params)\n",
    "    \n",
    "    # Compute best score\n",
    "    best_score = grid.best_score_\n",
    "\n",
    "    # Print best score\n",
    "    print(\"Best score: {:.5f}\".format(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a16641-d066-43a5-b957-cc9c1ed72988",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'n_estimators':[50, 200, 400, 800]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668692dd-957b-412c-9c61-98db89eb04a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'learning_rate':[0.01, 0.05, 0.2, 0.3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44791b5c-9782-47be-8d26-65e848bc312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'max_depth':[1, 2, 4, 8]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ba6aa-2f54-4f5c-a74a-fe0daeddf6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'subsample':[0.3, 0.5, 0.7, 0.9]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb4a428-f6d5-43c9-9c62-6c692c1ce4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'gamma':[0.05, 0.1, 0.5, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68274ff-09e6-436f-aa46-dd051b33b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'learning_rate':[0.001, 0.01, 0.03], 'max_depth':[1, 2], 'gamma':[0.025, 0.05, 0.5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd8620a-e79d-4e19-999f-9bd57bb43881",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'subsample':[0.3, 0.5, 0.7, 0.9, 1], \n",
    "                    'colsample_bylevel':[0.3, 0.5, 0.7, 0.9, 1], \n",
    "                    'colsample_bynode':[0.3, 0.5, 0.7, 0.9, 1], \n",
    "                    'colsample_bytree':[0.3, 0.5, 0.7, 0.9, 1]}, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54839756-277b-44ac-b0ac-1cc19f893eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#migrando para o dataset perfeitameente balanceado\n",
    "X_short = X.iloc[:74, :]\n",
    "y_short = y.iloc[:74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c9215c-572c-4a4c-9392-4d7c1b0b3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'max_depth':[1, 2, 3], 'colsample_bynode':[0.5, 0.75, 1]}, X=X_short, y=y_short, \n",
    "            model=XGBClassifier(random_state=2,verbosity=0,use_label_encoder=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e83e96-921d-451c-8d14-b85cb5ba2e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all dataset\n",
    "df_all = pd.read_csv('bases/exoplanets.csv')\n",
    "df_all['LABEL'] = df_all['LABEL'].replace(1, 0)\n",
    "df_all['LABEL'] = df_all['LABEL'].replace(2, 1)\n",
    "\n",
    "X_all = df_all.iloc[:,1:]\n",
    "y_all = df_all.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf2f49f-bc51-423d-9000-b250b7e6e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['LABEL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ae254a-1358-46bb-b99c-fb0eed01665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = int(5050/37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6617a767-7f54-47e2-b13a-50f4d0559032",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(scale_pos_weight=weight, random_state=2,verbosity=0)\n",
    "\n",
    "# Obtain scores of cross-validation\n",
    "scores = cross_val_score(model, X_all, y_all, cv=kfold, scoring='recall')\n",
    "\n",
    "# Display accuracy\n",
    "print('Recall:', scores)\n",
    "\n",
    "# Display mean accuracy\n",
    "print('Recall mean:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff26f48-cc7d-447d-b270-fbe8feddcbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'learning_rate':[0.001, 0.01]}, X=X_all, y=y_all, model=XGBClassifier(scale_pos_weight=weight, \n",
    "                                                                                          random_state=2,\n",
    "                                                                                         verbosity=0,\n",
    "                                                                                         use_label_encoder=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d93d0f2-47ed-4c1d-bfca-a5f1d61a8508",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'max_depth':[1, 2],'learning_rate':[0.001]}, X=X_all, y=y_all, \n",
    "            model=XGBClassifier(scale_pos_weight=weight, random_state=2,verbosity=0,use_label_encoder=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc59f8d-5cab-4c1a-9974-ef0d49360361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model(X, y, model):\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X_all)\n",
    "    score = recall_score(y_all, y_pred)\n",
    "    print(score)\n",
    "    print(confusion_matrix(y_all, y_pred))\n",
    "    print(classification_report(y_all, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0bcbaf-f7a5-4176-82a7-151a1858af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanceado = 74 linhas\n",
    "final_model(X_short, y_short, XGBClassifier(max_depth=2, colsample_by_node=0.5, random_state=2,\n",
    "                                            verbosity=0,use_label_encoder=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1fc5e3-b4b5-4d15-9bf5-86648b499bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 400 linhas\n",
    "final_model(X, y, XGBClassifier(max_depth=2, colsample_bynode=0.5, scale_pos_weight=10, random_state=2,\n",
    "                               verbosity=0,use_label_encoder=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e531c16-54c7-44d5-aecd-e671b776bc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todas as linhas\n",
    "final_model(X_all, y_all, XGBClassifier(max_depth=2, colsample_bynode=0.5, \n",
    "                                        scale_pos_weight=weight, \n",
    "                                        random_state=2,\n",
    "                                       verbosity=0,use_label_encoder=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b199fe85-9c58-4a4b-acd4-a77c9b638dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
