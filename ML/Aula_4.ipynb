{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "simple-aside",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-bermuda",
   "metadata": {},
   "source": [
    "Vamos pegar uma intuição do k-means inicialmente. Para tanto, vamos gerar algumas bolhas (como se fossem agrupamentos pra entender como o k-means poderia ser usado para agrupar esses dados). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-pittsburgh",
   "metadata": {},
   "source": [
    "Agora, vamos criar nossos dados. Especificamos a localização dos centróides e definimos o desvio padrão dos dados para cada cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_centers = np.array(\n",
    "    [[ 0.2,  2.3],\n",
    "     [-1.5 ,  2.3],\n",
    "     [-2.8,  1.8],\n",
    "     [-2.8,  2.8],\n",
    "     [-2.8,  1.3]])\n",
    "blob_std = np.array([0.4, 0.3, 0.1, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-tracker",
   "metadata": {},
   "source": [
    "Agora usamos o método make_blobs para criar as bolhas baseadas nas informações que passamos parâmetros. O método retorna os dados gerados bem como o rótulo de cada um (seu cluster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=2000, centers=blob_centers,\n",
    "                  cluster_std=blob_std, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-copper",
   "metadata": {},
   "source": [
    "Podemos criar uma função para visualizar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(X, y=None):\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=1)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-timing",
   "metadata": {},
   "source": [
    "E agora, fazemos o plot das bolhas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plot_clusters(X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-recipient",
   "metadata": {},
   "source": [
    "Agora, a ideia é treinar o k-means nesses dados e verificar se ele encontra esses grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-luxury",
   "metadata": {},
   "source": [
    "Para treinar o k-means, definimos o número de k. A partir desses dados, 5 é um número adequado. Entretanto, em problemas reais, a definição de k não é tão simples assim, como já vimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "y_pred = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-oxide",
   "metadata": {},
   "source": [
    "Podemos comparar os centróides obtidos pelo k-means com os centróides que definimos previamente ao criar os dados. Isso nos dará uma ideia da qualidade dos clusters formados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-welcome",
   "metadata": {},
   "source": [
    "Algo interessante de se fazer é plotar as fronteiras de decisão que o algoritmo encontrou e comparar com o plot original dos dados, o que nos permite identificar erros de atribuição a um determinado cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando as funções para visualizar as fronteiras de decisão\n",
    "def plot_data(X):\n",
    "    plt.plot(X[:, 0], X[:, 1], 'k.', markersize=2)\n",
    "\n",
    "def plot_centroids(centroids, weights=None, circle_color='w', cross_color='k'):\n",
    "    if weights is not None:\n",
    "        centroids = centroids[weights > weights.max() / 10]\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='o', s=35, linewidths=8,\n",
    "                color=circle_color, zorder=10, alpha=0.9)\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='x', s=2, linewidths=12,\n",
    "                color=cross_color, zorder=11, alpha=1)\n",
    "\n",
    "def plot_decision_boundaries(clusterer, X, resolution=1000, show_centroids=True,\n",
    "                             show_xlabels=True, show_ylabels=True):\n",
    "    mins = X.min(axis=0) - 0.1\n",
    "    maxs = X.max(axis=0) + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(mins[0], maxs[0], resolution),\n",
    "                         np.linspace(mins[1], maxs[1], resolution))\n",
    "    Z = clusterer.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),\n",
    "                cmap=\"Pastel2\")\n",
    "    plt.contour(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),\n",
    "                linewidths=1, colors='k')\n",
    "    plot_data(X)\n",
    "    if show_centroids:\n",
    "        plot_centroids(clusterer.cluster_centers_)\n",
    "\n",
    "    if show_xlabels:\n",
    "        plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "    if show_ylabels:\n",
    "        plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "    else:\n",
    "        plt.tick_params(labelleft=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-region",
   "metadata": {},
   "source": [
    "Agora podemos fazer o plot. O que vamos obter é conhecido como Diagrama de Voronoi, uma forma de representar clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plot_decision_boundaries(kmeans, X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-length",
   "metadata": {},
   "source": [
    "Compare essa figura com a figura original das bolhas. Consegue identificar erros de atribuição?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-leader",
   "metadata": {},
   "source": [
    "Fazer a predição de novas amostras é particularmente simples também:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[0, 2], [3, 2], [-3, 3], [-3, 2.5]])\n",
    "kmeans.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-cooper",
   "metadata": {},
   "source": [
    "# O Algoritmo K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-general",
   "metadata": {},
   "source": [
    "Depois de entendermos intuitivamente o K-means, é hora de nos aprofundarmos na maneira em que ele constrói clusters.\n",
    "\n",
    "Suponha que seja fornecido os centróides. Dessa maneira, poderíamos facilmente rotular todas as intâncias no dataset atribuindo a cada uma delas ao cluster cujo centróide seja o mais próximo. \n",
    "\n",
    "Alternativamente, se todos os rótulos das amostras foram fornecidos, poderíamos localizar os centróides calculando a média de todas as amostras para cada cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-longitude",
   "metadata": {},
   "source": [
    "Mas e se nada disso for fornecido? \n",
    "\n",
    "Podemos posicionar os centróides de maneira aleatória (selecionando k amostras aleatóriamente e usando suas localizações como centróides). Então, rotulamos as instâncias, atualizamos os centróides, rotulamos as instâncias, atualizamos os centróides e assim sucessivamente até que os centróides parem de se mover. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-matthew",
   "metadata": {},
   "source": [
    "Vamos executar o K-means para 1, 2 e 3 iterações e ver como os centróides vão se movendo bem como as instâncias atualizando seus rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-protocol",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_iter1 = KMeans(n_clusters=5, init=\"random\", n_init=1,\n",
    "                     algorithm=\"full\", max_iter=1, random_state=0)\n",
    "kmeans_iter2 = KMeans(n_clusters=5, init=\"random\", n_init=1,\n",
    "                     algorithm=\"full\", max_iter=2, random_state=0)\n",
    "kmeans_iter3 = KMeans(n_clusters=5, init=\"random\", n_init=1,\n",
    "                     algorithm=\"full\", max_iter=3, random_state=0)\n",
    "kmeans_iter1.fit(X)\n",
    "kmeans_iter2.fit(X)\n",
    "kmeans_iter3.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.subplot(321)\n",
    "plot_data(X)\n",
    "plot_centroids(kmeans_iter1.cluster_centers_, circle_color='r', cross_color='w')\n",
    "plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "plt.tick_params(labelbottom=False)\n",
    "plt.title(\"Update the centroids (initially randomly)\", fontsize=14)\n",
    "\n",
    "plt.subplot(322)\n",
    "plot_decision_boundaries(kmeans_iter1, X, show_xlabels=False, show_ylabels=False)\n",
    "plt.title(\"Label the instances\", fontsize=14)\n",
    "\n",
    "plt.subplot(323)\n",
    "plot_decision_boundaries(kmeans_iter1, X, show_centroids=False, show_xlabels=False)\n",
    "plot_centroids(kmeans_iter2.cluster_centers_)\n",
    "\n",
    "plt.subplot(324)\n",
    "plot_decision_boundaries(kmeans_iter2, X, show_xlabels=False, show_ylabels=False)\n",
    "\n",
    "plt.subplot(325)\n",
    "plot_decision_boundaries(kmeans_iter2, X, show_centroids=False)\n",
    "plot_centroids(kmeans_iter3.cluster_centers_)\n",
    "\n",
    "plt.subplot(326)\n",
    "plot_decision_boundaries(kmeans_iter3, X, show_ylabels=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-discharge",
   "metadata": {},
   "source": [
    "Vimos que, em poucas iterações, o k-means se aproximou da solução ótima. Entretanto, como vimos, o k-means é sensível a inicialização dos centróides, o que signifca que ele pode não convergir para a solução ótima. Vamos entender como podemos encontrar a solução ótima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-month",
   "metadata": {},
   "source": [
    "### Métodos de Inicialização dos Centróides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-riding",
   "metadata": {},
   "source": [
    "Se sabmos de antemão onde aproximadamente os centróides devem ser posicionados, podemos setar o parâmetro *init* a partir de um Numpy array e setar *n_init* igual a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_init = np.array([[-3,3],[-3,2],[-3,1],[-1,2],[0,2]])\n",
    "kmeans = KMeans(n_clusters=5, init=good_init, n_init=1)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plot_decision_boundaries(kmeans, X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-barcelona",
   "metadata": {},
   "source": [
    "Outra solução é executar o algoritmo múltiplas vezes com diferentes inicializações aleatórias e guardar a melhor solução, mas como sabemos que uma solução é a melhor?\n",
    "\n",
    "Temos uma métrica de performance que nos fornece essa informação: inercia do modelo, obtida através do parâmetro *inertia_*. Essa métrica nada mais é que distância média quadrática entre cada instância e o centróide mais próximo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-ballet",
   "metadata": {},
   "source": [
    "### Encontrando o número ótimo de clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-jones",
   "metadata": {},
   "source": [
    "Até o momento, definimos o número de cluster (k) igual a 5 porque é o número óbvio quando se olha os dados. Entretanto, de modo geral, não será fácil saber definir k e os resultados podem ser bem ruins se escolhermos o número incorreto de k. \n",
    "\n",
    "Observe o exemplo quando usamos k=3 e depois k=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusterer_comparison(clusterer1, clusterer2, X, title1=None, title2=None):\n",
    "    clusterer1.fit(X)\n",
    "    clusterer2.fit(X)\n",
    "\n",
    "    plt.figure(figsize=(10, 3.2))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plot_decision_boundaries(clusterer1, X)\n",
    "    if title1:\n",
    "        plt.title(title1, fontsize=14)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plot_decision_boundaries(clusterer2, X, show_ylabels=False)\n",
    "    if title2:\n",
    "        plt.title(title2, fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_k3 = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans_k8 = KMeans(n_clusters=8, random_state=42)\n",
    "\n",
    "plot_clusterer_comparison(kmeans_k3, kmeans_k8, X, \"$k=3$\", \"$k=8$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-person",
   "metadata": {},
   "source": [
    "E se usarmos a inércia para definir o número ótimo de clusters? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_per_k = [KMeans(n_clusters=k, random_state=42).fit(X)\n",
    "                for k in range(1, 10)]\n",
    "inertias = [model.inertia_ for model in kmeans_per_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3.5))\n",
    "plt.plot(range(1, 10), inertias, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Inertia\", fontsize=14)\n",
    "plt.axis([1, 8.5, 0, 1300])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-rainbow",
   "metadata": {},
   "source": [
    "Qual o problema dessa solução?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-surrey",
   "metadata": {},
   "source": [
    "Não podemos simplesmente usar o valor de k que minimiza a inércia visto que ela continuará diminuindo à medida que aumentamos o valor de k. \n",
    "\n",
    "De fato, quanto mais clusters existem, mais perto cada instância ficará do seu centróide e, portanto, menor o valor da iníercia. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-worth",
   "metadata": {},
   "source": [
    "#### Elbow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-original",
   "metadata": {},
   "source": [
    "Entretanto, ainda podemos usar a inércia para definir um valor adequado de clusters. Ao analisarmos o gráfico, observamos que o valor na inércia cai drásticamente à medida que aumentamos o valor de k até 4 e, então, o valor da inércia diminui muito mais lentamente a partir daí. Esta curva possui vagamente uma forma de um braço e possui um \"cotovelo\" (elbow) quando k=4. Assim, poderíamos usar k=4 para uma solução adequada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3.5))\n",
    "plt.plot(range(1, 10), inertias, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Inertia\", fontsize=14)\n",
    "plt.annotate('Elbow',\n",
    "             xy=(4, inertias[3]),\n",
    "             xytext=(0.55, 0.55),\n",
    "             textcoords='figure fraction',\n",
    "             fontsize=16,\n",
    "             arrowprops=dict(facecolor='black', shrink=0.1)\n",
    "            )\n",
    "plt.axis([1, 8.5, 0, 1300])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundaries(kmeans_per_k[4-1], X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-eleven",
   "metadata": {},
   "source": [
    "#### Silhouette"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-procurement",
   "metadata": {},
   "source": [
    "Uma outra, e melhor, abordagem para determinar o número de cluster é a partir do *silhouette coefficient*. Como vimos, esse coeficiente é dado pela seguinte equação:\n",
    "\n",
    "$\\frac{(b-a)}{max(a,b)}$\n",
    "\n",
    "em que:\n",
    "\n",
    "* é a distância média para outras amostras no mesmo cluster (distância média intra-cluster)\n",
    "* 𝑏 é a distância média do cluster mais próximo (distância média para as amostras do próximo cluster mais próximo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-ambassador",
   "metadata": {},
   "source": [
    "Para calcular o *silhouette score* podemos usar a função de mesmo nome da Scikit-Learn, fornecendo todas as amostras do dataset e seus respectivos rótulos aos quais foram atribuídos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "silhouette_score(X, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-subscription",
   "metadata": {},
   "source": [
    "Podemos comparar o valor desse score para diferentes números de clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = [silhouette_score(X, model.labels_)\n",
    "                     for model in kmeans_per_k[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(range(2, 10), silhouette_scores, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Silhouette score\", fontsize=14)\n",
    "plt.axis([1.8, 8.5, 0.55, 0.7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-disclaimer",
   "metadata": {},
   "source": [
    "Como podemos ver, esta visualização é muito mais rica que a anterior (usando *inertia*). Embora confirme que k=4 é uma ótima escolha (da mesma maneira que o gráfico anterior), mostra também que k=5 é uma excelente opção e muito melhor que k=6 ou k=7, o que não é visível quando usamos inércia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-cover",
   "metadata": {},
   "source": [
    "# Hierarchical Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-association",
   "metadata": {},
   "source": [
    "Para começar, vamos criar alguns dados para entender a formação dos dendrogramas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[5,3],\n",
    "    [10,15],\n",
    "    [15,12],\n",
    "    [24,10],\n",
    "    [30,30],\n",
    "    [85,70],\n",
    "    [71,80],\n",
    "    [60,78],\n",
    "    [70,55],\n",
    "    [80,91],])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-karma",
   "metadata": {},
   "source": [
    "Agora, vamos plotar esses dados para visualizar seu comportamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = range(1, 11)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.subplots_adjust(bottom=0.1)\n",
    "plt.scatter(X[:,0],X[:,1], label='True Position')\n",
    "\n",
    "for label, x, y in zip(labels, X[:, 0], X[:, 1]):\n",
    "    plt.annotate(\n",
    "        label,\n",
    "        xy=(x, y), xytext=(-3, 3),\n",
    "        textcoords='offset points', ha='right', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-advertising",
   "metadata": {},
   "source": [
    "É possível ver que esses dados formam dois cluster. A partir deles, vamos, então, desenhar os dendrogramas. A princípio, iremos usar a biblioteca scipy (de onde vem o numpy) para isso. Depois, vamos para Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-monday",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "linked = linkage(X, 'single')\n",
    "\n",
    "labelList = range(1, 11)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(linked,\n",
    "            orientation='top',\n",
    "            labels=labelList,\n",
    "            distance_sort='descending',\n",
    "            show_leaf_counts=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-paste",
   "metadata": {},
   "source": [
    "O algoritmo começa encontrando os dois pontos mais próximos um ao outro baseado na distância euclidiana. No caso, os pontos 2 e 3 são os mais próximos, por isso eles formam o primeiro cluster. \n",
    "\n",
    "Nos dendrogramas, a altura das barras de cada agrupamento determina o valor da distância euclidiana. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-london",
   "metadata": {},
   "source": [
    "## Hclust usando Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-treaty",
   "metadata": {},
   "source": [
    "Vamos agora usar a scikit learn para criar um cluster hierárquico. \n",
    "\n",
    "Primeiro, vamos criar os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[5,3],\n",
    "    [10,15],\n",
    "    [15,12],\n",
    "    [24,10],\n",
    "    [30,30],\n",
    "    [85,70],\n",
    "    [71,80],\n",
    "    [60,78],\n",
    "    [70,55],\n",
    "    [80,91],])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
    "cluster.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-geology",
   "metadata": {},
   "source": [
    "Observe que setamos o número de cluster *n_clusters* igual a 2, usamos a distância euclidiana para calcular a distância entre os pontos e linkage estamos usando a opção \"ward\", que se refere a minimização da variância dos clusters sendo agrupados. As outras opções são as que vimos em sala: single linkage, complete linkage e average linkage\n",
    "\n",
    "O método fit_predict() retorna o rótulo de cada instância"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-ceiling",
   "metadata": {},
   "source": [
    "Podemos plotar os dados originais pintando cada instância de acordo com o cluster a que ela foi atribuída:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0],X[:,1], c=cluster.labels_, cmap='rainbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-doubt",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=1000, noise=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.05, min_samples=5)\n",
    "dbscan.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan.labels_[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-mouth",
   "metadata": {},
   "source": [
    "Note que alguns rótulos possuem valor igual a -1, o que significa que eles são considerados anomalias pelo algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan.components_[:3] #core instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-liberia",
   "metadata": {},
   "source": [
    "Vamos treinar um novo DBSCAN, mas agora usando eps = 0.2 e comparar com o primeiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan2 = DBSCAN(eps=0.2)\n",
    "dbscan2.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#função auxiliar para plotar os cluster\n",
    "def plot_dbscan(dbscan, X, size, show_xlabels=True, show_ylabels=True):\n",
    "    core_mask = np.zeros_like(dbscan.labels_, dtype=bool)\n",
    "    core_mask[dbscan.core_sample_indices_] = True\n",
    "    anomalies_mask = dbscan.labels_ == -1\n",
    "    non_core_mask = ~(core_mask | anomalies_mask)\n",
    "\n",
    "    cores = dbscan.components_\n",
    "    anomalies = X[anomalies_mask]\n",
    "    non_cores = X[non_core_mask]\n",
    "    \n",
    "    plt.scatter(cores[:, 0], cores[:, 1],\n",
    "                c=dbscan.labels_[core_mask], marker='o', s=size, cmap=\"Paired\")\n",
    "    plt.scatter(cores[:, 0], cores[:, 1], marker='*', s=20, c=dbscan.labels_[core_mask])\n",
    "    plt.scatter(anomalies[:, 0], anomalies[:, 1],\n",
    "                c=\"r\", marker=\"x\", s=100)\n",
    "    plt.scatter(non_cores[:, 0], non_cores[:, 1], c=dbscan.labels_[non_core_mask], marker=\".\")\n",
    "    if show_xlabels:\n",
    "        plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "    if show_ylabels:\n",
    "        plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "    else:\n",
    "        plt.tick_params(labelleft=False)\n",
    "    plt.title(\"eps={:.2f}, min_samples={}\".format(dbscan.eps, dbscan.min_samples), fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 3.2))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_dbscan(dbscan, X, size=100)\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_dbscan(dbscan2, X, size=600, show_ylabels=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-rolling",
   "metadata": {},
   "source": [
    "Surpreendentemente, o DBSCAN não possui um método *predict()*, embora possua um método *fit_predict()*. Em outras palavras, não é possível predizer a qual cluster uma nova amostra pertence. Esta decisão de implementação foi feita porque difernetes algoritmos de classificação podem ser melhores para diferentes tarefas, então os autores decidiram deixar o usuário escolher. \n",
    "\n",
    "Entretanto, não é difícil de implementar. Por exemplo, podemos treinar um KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=50)\n",
    "knn.fit(dbscan.components_, dbscan.labels_[dbscan.core_sample_indices_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-warner",
   "metadata": {},
   "source": [
    "obs: core_sample_indices_ contém os índices das instâncias *core*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[-0.5, 0], [0, 0.5], [1, -0.1], [2, 1]])\n",
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict_proba(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-minister",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
