{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"decision_trees\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    " \n",
    "iris = load_iris()\n",
    "X = iris.data[:, 2:] # petal length and width\n",
    "y = iris.target\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "tree_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível visualizar a árvore de decisão treinada usando o método export_graphviz(). \n",
    "OBS: Verifique se o pacote está instalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "def image_path(fig_id):\n",
    "    return os.path.join(IMAGES_PATH, fig_id)\n",
    "\n",
    "export_graphviz(\n",
    "        tree_clf,\n",
    "        out_file=image_path(\"iris_tree.dot\"),\n",
    "        feature_names=iris.feature_names[2:],\n",
    "        class_names=iris.target_names,\n",
    "        rounded=True,\n",
    "        filled=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vá em File -> New -> Terminal:\n",
    "\n",
    "1. Navegue até a pasta onde o arquivo ires_tree.dot foi gerado \n",
    "2. Execute o seguinte código: dot -Tpng .\\iris_tree.dot -o iris_tree.png\n",
    "\n",
    "Isso vai gerar um arquivo png que mostrará como ficou nossa árvore. Vou adicioná-la aqui para facilitar nosso entendimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"iris_tree.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como o classificador realiza novas predições?\n",
    "\n",
    "- Começando pela raiz, verifique se o comprimento da pétala é menor que 2.45cm.\n",
    "\n",
    "    - Se for, vá para o nó da esquerda. Como é um nó folha, a árvore prediz que a classe é setosa\n",
    "    \n",
    "    - Se não, vá para o nó da direita. Verifique se a largura da folha é menor que 1.75cm.\n",
    "    \n",
    "        - Se for, vá para o nó folha da esquerda. A flor será classificada como versicolor\n",
    "        \n",
    "        - Se não, vá para o nó folha da direita. A flor será classificada como virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desicion Boundaries\n",
    "É possível verificar as fronteiras de decisão que o arquivo encontrou na construção da árvore. O código abaixo nos fornece uma visualização. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_boundary(clf, X, y, axes=[0, 7.5, 0, 3], iris=True, legend=False, plot_training=True):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if not iris:\n",
    "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
    "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
    "    if plot_training:\n",
    "        plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", label=\"Iris setosa\")\n",
    "        plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", label=\"Iris versicolor\")\n",
    "        plt.plot(X[:, 0][y==2], X[:, 1][y==2], \"g^\", label=\"Iris virginica\")\n",
    "        plt.axis(axes)\n",
    "    if iris:\n",
    "        plt.xlabel(\"Petal length\", fontsize=14)\n",
    "        plt.ylabel(\"Petal width\", fontsize=14)\n",
    "    else:\n",
    "        plt.xlabel(r\"$x_1$\", fontsize=18)\n",
    "        plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)\n",
    "    if legend:\n",
    "        plt.legend(loc=\"lower right\", fontsize=14)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plot_decision_boundary(tree_clf, X, y)\n",
    "plt.plot([2.45, 2.45], [0, 3], \"k-\", linewidth=2)\n",
    "plt.plot([2.45, 7.5], [1.75, 1.75], \"k--\", linewidth=2)\n",
    "plt.plot([4.95, 4.95], [0, 1.75], \"k:\", linewidth=2)\n",
    "plt.plot([4.85, 4.85], [1.75, 3], \"k:\", linewidth=2)\n",
    "plt.text(1.40, 1.0, \"Depth=0\", fontsize=15)\n",
    "plt.text(3.2, 1.80, \"Depth=1\", fontsize=13)\n",
    "plt.text(4.05, 0.5, \"(Depth=2)\", fontsize=11)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linha mais grossa representa a fronteira de decisão do nó raiz: petal length = 2.45cm. Como a área à esquerda é pura, não há mais splits. Entretanto, a área à direita é impura, então o nó é dividido quando petal eidth = 1.75cm. Visto que max_depth=2, Decision Tree para aqui. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimando as probabilidades das classes\n",
    "\n",
    "Uma Árvore de Decisão pode estimar a probabilidade de uma instância pertencer a uma classe particular. Suponha que uma flor tenha 5cm de comprimento e 1.5cm de largura. O nó correspondente seria o Depth-2 a esquerda. Nesse caso, a Árvore retornaria as seguintes probabilidades:\n",
    "\n",
    "- 0% parra *Iris Setosa* (0/54)\n",
    "- 90.7% para *Iris Versicolor* (49/54)\n",
    "- 9.3% para Iris Virginica* (5/54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf.predict_proba([[5, 1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E se você solicitar a predição da classe, o algoritmo retornará *Iris versicolor* (classe 1), visto que ela possui a maior probabilidade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf.predict([[5, 1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularização dos Hiperparâmetros\n",
    "\n",
    "Árvores de decisão assumem poucas suposições acerca dos dados de treinamento (ao contrário dos modelos lineares, que assumem que os dados são lineares). Se deixada sem restrição, a árvore irá se adaptar aos dados de treino, dando um fit muito próximo (na verdade, overfit). \n",
    "\n",
    "Tais modelos são chamados não-paramétricos, mas não porque não possuem parâmetros (ou hiperparâmetros), mas porque o número de parâmetros não é determinado antes do treino.\n",
    "\n",
    "PAra evitar overfitting, é preciso restringir a liberdade da Árvore de Decisão durante o treinamento. Isto é chamado de regularização. Alguns hiperparâmetros que podem ser ajustados para evitar overfitting numa Árvore de decisão:\n",
    "\n",
    "- max_depth (profundidade máxima da árvore - delimita o número de splits)\n",
    "- min_samples_split (número mínimo de amostras que um nó deve ter antes do split)\n",
    "- min_sampes_leaf (número mínimo de amostras que um nó folha deve ter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo apresenta duas Árvores treinadas no dataset moons. A da esquerda foi treinada com hiperparâmetros padrões (sem restrições), enquanto a da direita foi regularizada (min_samples_leaf=4). \n",
    "\n",
    "Podemos observar que o modelo da esquerda está dando overfiting e que o modelo da direita irá generalizar melhor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "Xm, ym = make_moons(n_samples=100, noise=0.25, random_state=53)\n",
    "\n",
    "deep_tree_clf1 = DecisionTreeClassifier(random_state=42)\n",
    "deep_tree_clf2 = DecisionTreeClassifier(min_samples_leaf=4,max_depth=3 random_state=42)\n",
    "deep_tree_clf1.fit(Xm, ym)\n",
    "deep_tree_clf2.fit(Xm, ym)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "plt.sca(axes[0])\n",
    "plot_decision_boundary(deep_tree_clf1, Xm, ym, axes=[-1.5, 2.4, -1, 1.5], iris=False)\n",
    "plt.title(\"No restrictions\", fontsize=16)\n",
    "plt.sca(axes[1])\n",
    "plot_decision_boundary(deep_tree_clf2, Xm, ym, axes=[-1.5, 2.4, -1, 1.5], iris=False)\n",
    "plt.title(\"min_samples_leaf = {}\".format(deep_tree_clf2.min_samples_leaf), fontsize=14)\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formas de Validação - k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', header=None)\n",
    "df_census.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation',\n",
    "                  'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', \n",
    "                   'income']\n",
    "df_census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando olhamos para o dataset, vemos a coluna 'education' e 'education_num'. A última é a versão numérica da primeira. Assim, podemos dropar 'education'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census = df_census.drop(['education'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas as colunas precisam ser transformadas em colunas numéricas. O método *get_dumies* do pandas pega valores únicos não-numéricos de cada coluna e os converte em colunas, com 1 indicando presença e 0 ausência. Veja o exemplo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exemplo\n",
    "pd.get_dummies(df_census['marital-status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census = pd.get_dummies(df_census)\n",
    "df_census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo (coluna target) é determinar se uma pessoa ganha mais que 50k ou não. Depois do pd.get_dummies, duas colunas, df_census['income_<=50k'] e df_census['income_>50k] são usadas para determinar se uma pessoa ganha 50k. Visto que ambas representam a mesma coisa, vamos deletar a primeira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census = df_census.drop('income_ <=50K', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features e labels\n",
    "X = df_census.iloc[:,:-1]\n",
    "y = df_census.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#uma função para executar cross-validation\n",
    "def cross_val(classifier, num_splits=10):\n",
    "    model = classifier\n",
    "    scores = cross_val_score(model, X, y, cv=num_splits)\n",
    "    print('Accuracy:', np.round(scores, 2))\n",
    "    print('Accuracy mean: %0.2f' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val((DecisionTreeClassifier()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
